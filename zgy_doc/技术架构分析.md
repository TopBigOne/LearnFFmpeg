# LearnFFmpeg 项目技术架构分析

## 目录

1. [项目概述](#1-项目概述)
2. [整体架构设计](#2-整体架构设计)
3. [核心模块详解](#3-核心模块详解)
4. [技术栈分析](#4-技术栈分析)
5. [数据流与时序分析](#5-数据流与时序分析)
6. [关键技术实现](#6-关键技术实现)
7. [性能优化策略](#7-性能优化策略)
8. [代码组织结构](#8-代码组织结构)

---

## 1. 项目概述

### 1.1 项目定位
LearnFFmpeg 是一个专注于 Android 平台音视频开发的教学项目，通过 FFmpeg 库实现了完整的音视频播放、录制、编辑功能。

### 1.2 核心功能
- 多种渲染方式的视频播放器（ANativeWindow、OpenGL ES、VR 3D）
- 音频播放与可视化
- 视频录制与编码（支持 H.264）
- 音频录制与编码（支持 AAC）
- 视频滤镜处理
- 音视频同步（三种策略）
- 硬件解码支持（MediaCodec）
- 流媒体播放

### 1.3 技术指标
- **最小 SDK**: Android 5.0 (API 21)
- **目标 SDK**: Android 10 (API 29)
- **支持架构**: ARM64-v8a, ARMv7
- **NDK版本**: r21
- **编译工具**: CMake 3.4.1+

---

## 2. 整体架构设计

### 2.1 分层架构

```
┌─────────────────────────────────────────────────────────┐
│                   应用层 (Java/Kotlin)                   │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐              │
│  │ Activity │  │  Adapter │  │   View   │              │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘              │
└───────┼────────────┼────────────┼────────────────────────┘
        │            │            │
        └────────────┴────────────┘
                     │ JNI
┌────────────────────┼────────────────────────────────────┐
│                    ▼                                     │
│              Native 接口层                               │
│           (learn-ffmpeg.cpp)                            │
│                                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │            PlayerWrapper                         │   │
│  │  ┌──────────────┐  ┌──────────────┐            │   │
│  │  │FFMediaPlayer │  │HWCodecPlayer │            │   │
│  │  └──────────────┘  └──────────────┘            │   │
│  └──────────────────────────────────────────────────┘   │
│                                                          │
│  ┌────────────────┐         ┌────────────────┐          │
│  │  播放器模块     │         │  录制模块       │          │
│  │  ┌──────────┐ │         │  ┌──────────┐  │          │
│  │  │ Decoder  │ │         │  │ Recorder │  │          │
│  │  └──────────┘ │         │  └──────────┘  │          │
│  │  ┌──────────┐ │         │  ┌──────────┐  │          │
│  │  │  Render  │ │         │  │ Encoder  │  │          │
│  │  └──────────┘ │         │  └──────────┘  │          │
│  └────────────────┘         └────────────────┘          │
│                                                          │
└──────────────────────────────────────────────────────────┘
                     │
                     ▼
┌──────────────────────────────────────────────────────────┐
│                FFmpeg 库 & Android Native API            │
│  ┌──────┐ ┌──────┐ ┌──────┐ ┌────────┐ ┌──────────┐   │
│  │avcodec│ │avformat│ │avfilter│ │OpenSLES│ │MediaCodec│   │
│  └──────┘ └──────┘ └──────┘ └────────┘ └──────────┘   │
└──────────────────────────────────────────────────────────┘
```

### 2.2 设计模式应用

#### 2.2.1 策略模式（Strategy Pattern）
- **应用场景**: 渲染器的选择
- **实现**:
  - 抽象接口: `VideoRender`, `AudioRender`
  - 具体策略: `NativeRender`, `VideoGLRender`, `VRGLRender`, `OpenSLRender`
  - 动态切换不同的渲染实现

#### 2.2.2 模板方法模式（Template Method）
- **应用场景**: 解码器基类
- **实现**: `DecoderBase` 定义解码流程框架
  - `Init()` - 初始化
  - `DecodingLoop()` - 解码循环（模板方法）
  - `OnFrameAvailable()` - 具体子类实现

#### 2.2.3 单例模式（Singleton）
- **应用场景**: GL渲染器
- **实现**: `VideoGLRender::GetInstance()`, `VRGLRender::GetInstance()`

#### 2.2.4 包装器模式（Wrapper）
- **应用场景**: 播放器统一接口
- **实现**: `PlayerWrapper` 统一封装 `FFMediaPlayer` 和 `HWCodecPlayer`

---

## 3. 核心模块详解

### 3.1 播放器模块（Player Module）

#### 3.1.1 类图结构

```
              MediaPlayer (Interface)
                    ▲
                    │
        ┌───────────┴───────────┐
        │                       │
   FFMediaPlayer          HWCodecPlayer
        │                       │
        │                       │
    ┌───┴───┐              使用 MediaCodec
    │       │              硬件解码
VideoDecoder AudioDecoder
    │       │
    └───┬───┘
        │ extends
   DecoderBase
```

#### 3.1.2 FFMediaPlayer 核心实现

```cpp
// 文件: app/src/main/cpp/player/FFMediaPlayer.cpp

void FFMediaPlayer::Init(JNIEnv *jniEnv, jobject obj,
                         char *url, int videoRenderType, jobject surface) {
    // 1. 创建解码器
    m_VideoDecoder = new VideoDecoder(url);
    m_AudioDecoder = new AudioDecoder(url);

    // 2. 根据渲染类型创建渲染器（策略模式）
    if(videoRenderType == VIDEO_RENDER_OPENGL) {
        m_VideoDecoder->SetVideoRender(VideoGLRender::GetInstance());
    } else if (videoRenderType == VIDEO_RENDER_ANWINDOW) {
        m_VideoRender = new NativeRender(jniEnv, surface);
        m_VideoDecoder->SetVideoRender(m_VideoRender);
    } else if (videoRenderType == VIDEO_RENDER_3D_VR) {
        m_VideoDecoder->SetVideoRender(VRGLRender::GetInstance());
    }

    // 3. 创建音频渲染器
    m_AudioRender = new OpenSLRender();
    m_AudioDecoder->SetAudioRender(m_AudioRender);

    // 4. 设置回调
    m_VideoDecoder->SetMessageCallback(this, PostMessage);
    m_AudioDecoder->SetMessageCallback(this, PostMessage);
}
```

#### 3.1.3 解码器架构（DecoderBase）

**核心成员变量**:
```cpp
class DecoderBase : public Decoder {
protected:
    AVFormatContext *m_AVFormatContext;  // 封装格式上下文
    AVCodecContext  *m_AVCodecContext;   // 解码器上下文
    AVCodec         *m_AVCodec;          // 解码器
    AVPacket        *m_Packet;           // 编码数据包
    AVFrame         *m_Frame;            // 解码后的帧

    long m_CurTimeStamp;                 // 当前播放时间
    long m_StartTimeStamp;               // 起始时间
    long m_Duration;                     // 总时长

    int  m_StreamIndex;                  // 流索引
    volatile int m_DecoderState;         // 解码器状态

    thread *m_Thread;                    // 解码线程
    mutex m_Mutex;                       // 互斥锁
    condition_variable m_Cond;           // 条件变量
};
```

**解码流程**:
```cpp
void DecoderBase::DecodingLoop() {
    while(m_DecoderState == STATE_DECODING) {
        // 1. 读取并解码一个 Packet
        int ret = DecodeOnePacket();

        // 2. 音视频同步
        long delayTime = AVSync();

        // 3. 延时控制
        if(delayTime > 0) {
            av_usleep(delayTime * 1000);
        }
    }
}
```

### 3.2 录制模块（Recorder Module）

#### 3.2.1 录制架构

```
MediaRecorderContext (统一调度)
        │
        ├── SingleVideoRecorder (视频录制)
        │   ├── GLCameraRender (相机渲染)
        │   └── MediaRecorder (编码封装)
        │
        └── SingleAudioRecorder (音频录制)
            └── MediaRecorder (编码封装)
```

#### 3.2.2 MediaRecorder 核心实现

**初始化流程**:
```cpp
int MediaRecorder::StartRecord() {
    // 1. 分配输出格式上下文
    avformat_alloc_output_context2(&m_FormatCtx, NULL, NULL, m_OutUrl);

    // 2. 添加音视频流
    if (m_OutputFormat->video_codec != AV_CODEC_ID_NONE) {
        AddStream(&m_VideoStream, m_FormatCtx, &m_VideoCodec,
                  m_OutputFormat->video_codec);
    }
    if (m_OutputFormat->audio_codec != AV_CODEC_ID_NONE) {
        AddStream(&m_AudioStream, m_FormatCtx, &m_AudioCodec,
                  m_OutputFormat->audio_codec);
    }

    // 3. 打开编码器
    OpenVideo(m_FormatCtx, m_VideoCodec, &m_VideoStream);
    OpenAudio(m_FormatCtx, m_AudioCodec, &m_AudioStream);

    // 4. 打开输出文件
    avio_open(&m_FormatCtx->pb, m_OutUrl, AVIO_FLAG_WRITE);

    // 5. 写入文件头
    avformat_write_header(m_FormatCtx, nullptr);

    // 6. 启动编码线程
    m_pMediaThread = new thread(StartMediaEncodeThread, this);
}
```

**编码流程**:
```cpp
int MediaRecorder::OnFrame2Encode(VideoFrame *inputFrame) {
    // 1. 复制帧数据
    VideoFrame *pImage = new VideoFrame();
    NativeImageUtil::CopyNativeImage(inputFrame, pImage);

    // 2. 推入编码队列
    m_VideoFrameQueue.Push(pImage);

    return 0;
}
```

### 3.3 渲染模块（Render Module）

#### 3.3.1 渲染器类型

| 渲染器 | 类型 | 应用场景 | 实现方式 |
|--------|------|---------|---------|
| NativeRender | 视频 | 原生窗口渲染 | ANativeWindow |
| VideoGLRender | 视频 | OpenGL渲染 + 滤镜 | OpenGL ES 3.0 |
| VRGLRender | 视频 | VR 全景播放 | OpenGL ES 3.0 球面映射 |
| OpenSLRender | 音频 | 音频播放 | OpenSL ES |
| AudioGLRender | 音频 | 音频可视化 | OpenGL ES 3.0 |

#### 3.3.2 VideoGLRender 实现细节

**OpenGL 渲染流程**:
```
1. 初始化 EGL 环境
   ├── eglGetDisplay()
   ├── eglInitialize()
   └── eglCreateContext()

2. 编译着色器
   ├── 顶点着色器 (Vertex Shader)
   └── 片元着色器 (Fragment Shader)

3. YUV → RGB 转换
   ├── 创建 Y、U、V 三个纹理
   ├── 上传 YUV 数据
   └── 在片元着色器中转换

4. 滤镜处理
   ├── 使用 AVFilter
   └── 实时应用滤镜效果

5. 渲染到屏幕
   └── eglSwapBuffers()
```

**YUV转RGB着色器**:
```glsl
// Fragment Shader
precision mediump float;
varying vec2 v_texCoord;
uniform sampler2D y_texture;
uniform sampler2D u_texture;
uniform sampler2D v_texture;

void main() {
    float y = texture2D(y_texture, v_texCoord).r;
    float u = texture2D(u_texture, v_texCoord).r - 0.5;
    float v = texture2D(v_texture, v_texCoord).r - 0.5;

    float r = y + 1.403 * v;
    float g = y - 0.344 * u - 0.714 * v;
    float b = y + 1.770 * u;

    gl_FragColor = vec4(r, g, b, 1.0);
}
```

### 3.4 公共模块（Common Module）

#### 3.4.1 AVPacketQueue（数据包队列）

**功能**: 线程安全的 AVPacket 缓冲队列

**核心实现**:
```cpp
class AVPacketQueue {
private:
    AVPacketNode *first_pkt;      // 队列头
    AVPacketNode *last_pkt;       // 队列尾
    int nb_packets;               // 包数量
    int size;                     // 队列大小
    mutex m_Mutex;                // 互斥锁
    condition_variable m_CondVar; // 条件变量

public:
    int PushPacket(AVPacket *pkt) {
        unique_lock<mutex> lock(m_Mutex);
        int ret = Put(pkt);
        m_CondVar.notify_all();  // 通知等待线程
        return ret;
    }

    int PopPacket(AVPacket *pkt, int block) {
        unique_lock<mutex> lock(m_Mutex);
        while(first_pkt == nullptr && !abort_request) {
            if(!block) return -1;
            m_CondVar.wait(lock);  // 阻塞等待
        }
        // ... 取出数据
    }
};
```

---

## 4. 技术栈分析

### 4.1 FFmpeg 库集成

#### 4.1.1 使用的 FFmpeg 库

| 库名 | 功能 | 应用场景 |
|------|------|---------|
| libavcodec | 编解码器 | 音视频编解码 |
| libavformat | 封装格式 | 文件读写、流解析 |
| libavfilter | 滤镜 | 视频特效、音频处理 |
| libswresample | 音频重采样 | 音频格式转换 |
| libswscale | 图像缩放 | 视频格式转换、缩放 |
| libavutil | 工具库 | 公共函数、数学运算 |

#### 4.1.2 第三方编解码器

```cmake
# CMakeLists.txt
set(third-party-libs
    avformat
    avcodec
    avfilter
    swresample
    swscale
    avutil
    fdk-aac    # AAC 音频编码器
    x264       # H.264 视频编码器
)
```

### 4.2 Android Native API

#### 4.2.1 图形渲染

| API | 用途 | 代码位置 |
|-----|------|---------|
| ANativeWindow | 原生窗口渲染 | NativeRender.cpp |
| EGL | OpenGL 上下文管理 | VideoGLRender.cpp |
| OpenGL ES 3.0 | GPU渲染、滤镜 | VideoGLRender.cpp, VRGLRender.cpp |

#### 4.2.2 音频播放

| API | 用途 | 代码位置 |
|-----|------|---------|
| OpenSL ES | 低延迟音频播放 | OpenSLRender.cpp |
| AudioTrack | Java层音频播放 | FFMediaPlayer.java |

#### 4.2.3 硬件编解码

| API | 用途 | 代码位置 |
|-----|------|---------|
| MediaCodec | 硬件解码 | HWCodecPlayer.cpp |

### 4.3 多线程并发

#### 4.3.1 线程模型

```
主线程 (UI Thread)
    │
    ├── 视频解码线程 (VideoDecoder Thread)
    │   └── 循环读取、解码视频帧
    │
    ├── 音频解码线程 (AudioDecoder Thread)
    │   └── 循环读取、解码音频帧
    │
    ├── OpenGL 渲染线程 (GL Thread)
    │   └── 渲染视频帧
    │
    ├── 视频编码线程 (Video Encode Thread)
    │   └── 编码视频帧
    │
    └── 音频编码线程 (Audio Encode Thread)
        └── 编码音频帧
```

#### 4.3.2 同步机制

**互斥锁 (mutex)**:
```cpp
mutex m_Mutex;
{
    unique_lock<mutex> lock(m_Mutex);
    // 临界区代码
}
```

**条件变量 (condition_variable)**:
```cpp
condition_variable m_Cond;

// 生产者
{
    unique_lock<mutex> lock(m_Mutex);
    m_Queue.push(data);
    m_Cond.notify_all();  // 通知消费者
}

// 消费者
{
    unique_lock<mutex> lock(m_Mutex);
    while(m_Queue.empty()) {
        m_Cond.wait(lock);  // 等待数据
    }
    data = m_Queue.pop();
}
```

---

## 5. 数据流与时序分析

### 5.1 播放流程时序图

```
Java层           JNI层              解码器             渲染器
  │               │                  │                  │
  ├─ init() ─────>│                  │                  │
  │               ├─ new Decoder ───>│                  │
  │               ├─ new Render ──────────────────────>│
  │               ├─ SetRender ─────>│                  │
  │               │                  │                  │
  ├─ play() ─────>│                  │                  │
  │               ├─ Start() ───────>│                  │
  │               │                  ├─ 启动解码线程     │
  │               │                  │                  │
  │               │                  ├─ avformat_open_input()
  │               │                  ├─ avformat_find_stream_info()
  │               │                  ├─ avcodec_open2()
  │               │                  │                  │
  │               │                  │ [解码循环开始]    │
  │               │                  ├─ av_read_frame()
  │               │                  ├─ avcodec_send_packet()
  │               │                  ├─ avcodec_receive_frame()
  │               │                  │                  │
  │               │                  ├─ OnFrameAvailable()─>│
  │               │                  │                  ├─ RenderVideoFrame()
  │               │                  │                  ├─ OpenGL 渲染
  │               │                  │                  │
  │               │                  ├─ AVSync() 音视频同步
  │               │                  ├─ av_usleep() 延时
  │               │                  │                  │
  │               │                  │ [循环...]        │
  │               │                  │                  │
  ├─ stop() ─────>│                  │                  │
  │               ├─ Stop() ────────>│                  │
  │               │                  ├─ 退出解码线程     │
  │               │                  │                  │
  ├─ uninit() ───>│                  │                  │
  │               ├─ delete Decoder ─┤                  │
  │               ├─ delete Render ─────────────────────┤
```

### 5.2 录制流程时序图

```
Java层           JNI层              录制器             编码器
  │               │                  │                  │
  ├─ startRecord()>│                  │                  │
  │               ├─ StartRecord() ─>│                  │
  │               │                  ├─ avformat_alloc_output_context2()
  │               │                  ├─ AddStream()     │
  │               │                  ├─ avcodec_open2()─>│
  │               │                  ├─ avio_open()     │
  │               │                  ├─ avformat_write_header()
  │               │                  ├─ 启动编码线程     │
  │               │                  │                  │
  │ [相机回调]     │                  │                  │
  ├─ onFrame() ──>│                  │                  │
  │               ├─ OnFrame2Encode()>│                  │
  │               │                  ├─ 推入帧队列       │
  │               │                  │                  │
  │               │                  │ [编码线程]        │
  │               │                  ├─ 从队列取帧       │
  │               │                  ├─ 图像格式转换     │
  │               │                  ├─ avcodec_send_frame()─>│
  │               │                  ├─ avcodec_receive_packet()<┤
  │               │                  ├─ av_interleaved_write_frame()
  │               │                  │                  │
  │               │                  │ [循环...]        │
  │               │                  │                  │
  ├─ stopRecord()>│                  │                  │
  │               ├─ StopRecord() ──>│                  │
  │               │                  ├─ 退出编码线程     │
  │               │                  ├─ av_write_trailer()
  │               │                  ├─ avio_close()    │
```

### 5.3 数据流转换

#### 5.3.1 视频播放数据流

```
文件/网络流
    │
    ├─ avformat_open_input()
    ▼
封装格式数据 (MP4/FLV/TS)
    │
    ├─ av_read_frame()
    ▼
编码数据包 (AVPacket - H.264/H.265)
    │
    ├─ avcodec_send_packet()
    ├─ avcodec_receive_frame()
    ▼
原始视频帧 (AVFrame - YUV420P)
    │
    ├─ sws_scale() [可选：格式转换]
    ▼
渲染数据 (YUV/RGBA)
    │
    ├─ OpenGL 纹理上传
    ├─ 着色器 YUV→RGB
    ▼
屏幕显示
```

#### 5.3.2 视频录制数据流

```
相机/屏幕采集
    │
    ▼
原始视频帧 (NV21/RGBA)
    │
    ├─ sws_scale() 格式转换
    ▼
标准格式帧 (YUV420P)
    │
    ├─ 滤镜处理 [可选]
    ▼
编码输入帧 (AVFrame)
    │
    ├─ avcodec_send_frame()
    ├─ avcodec_receive_packet()
    ▼
编码数据包 (AVPacket - H.264)
    │
    ├─ av_interleaved_write_frame()
    ▼
封装输出文件 (MP4)
```

---

## 6. 关键技术实现

### 6.1 音视频同步

#### 6.1.1 三种同步策略

**1. 视频同步到音频（默认方式）**
```cpp
long DecoderBase::AVSync() {
    // 获取音频当前播放时间
    long audioClock = m_AVSyncCallback(m_AVDecoderContext);

    // 计算视频帧应该显示的时间
    long videoClock = m_CurTimeStamp;

    // 计算差值
    long diff = videoClock - audioClock;

    // 返回需要延时的时间
    return diff;
}
```

**2. 音频同步到视频**
- 通过调整音频播放速率实现

**3. 同步到外部时钟**
- 使用系统时钟作为参考

#### 6.1.2 PTS（Presentation Time Stamp）处理

```cpp
void DecoderBase::UpdateTimeStamp() {
    if(m_Frame->pts != AV_NOPTS_VALUE) {
        // 将 PTS 转换为毫秒
        m_CurTimeStamp = m_Frame->pts * 1000 *
            av_q2d(m_AVFormatContext->streams[m_StreamIndex]->time_base);
    }
}
```

### 6.2 视频滤镜实现

#### 6.2.1 FFmpeg AVFilter 使用

```cpp
// 初始化滤镜图
AVFilterGraph *filter_graph = avfilter_graph_alloc();

// 创建 buffer 输入源
avfilter_graph_create_filter(&buffersrc_ctx, buffersrc, "in",
    args, NULL, filter_graph);

// 创建 buffersink 输出
avfilter_graph_create_filter(&buffersink_ctx, buffersink, "out",
    NULL, NULL, filter_graph);

// 解析滤镜描述字符串
avfilter_graph_parse_ptr(filter_graph, filters_descr,
    &inputs, &outputs, NULL);

// 配置滤镜图
avfilter_graph_config(filter_graph, NULL);

// 使用滤镜
av_buffersrc_add_frame(buffersrc_ctx, frame);
av_buffersink_get_frame(buffersink_ctx, filt_frame);
```

#### 6.2.2 常用滤镜效果

| 滤镜名 | 效果 | 描述字符串示例 |
|--------|------|---------------|
| vflip | 垂直翻转 | "vflip" |
| hflip | 水平翻转 | "hflip" |
| negate | 反色 | "negate" |
| edgedetect | 边缘检测 | "edgedetect" |
| boxblur | 模糊 | "boxblur=2:1" |

### 6.3 硬件加速解码

#### 6.3.1 MediaCodec 硬解码流程

```cpp
// 1. 创建 MediaCodec
AMediaCodec *codec = AMediaCodec_createDecoderByType("video/avc");

// 2. 配置
AMediaCodec_configure(codec, format, surface, NULL, 0);

// 3. 启动
AMediaCodec_start(codec);

// 4. 解码循环
while(decoding) {
    // 获取输入缓冲区
    ssize_t idx = AMediaCodec_dequeueInputBuffer(codec, timeout);
    if(idx >= 0) {
        // 写入编码数据
        uint8_t *buf = AMediaCodec_getInputBuffer(codec, idx, &bufsize);
        memcpy(buf, data, size);
        AMediaCodec_queueInputBuffer(codec, idx, 0, size, pts, 0);
    }

    // 获取输出
    idx = AMediaCodec_dequeueOutputBuffer(codec, &info, timeout);
    if(idx >= 0) {
        // 渲染到 Surface
        AMediaCodec_releaseOutputBuffer(codec, idx, true);
    }
}
```

### 6.4 OpenGL 渲染优化

#### 6.4.1 纹理上传优化

```cpp
// 使用 PBO (Pixel Buffer Object) 异步上传纹理
GLuint pbo;
glGenBuffers(1, &pbo);
glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pbo);
glBufferData(GL_PIXEL_UNPACK_BUFFER, size, nullptr, GL_STREAM_DRAW);

// 映射缓冲区
void* ptr = glMapBufferRange(GL_PIXEL_UNPACK_BUFFER, 0, size,
    GL_MAP_WRITE_BIT | GL_MAP_INVALIDATE_BUFFER_BIT);
memcpy(ptr, data, size);
glUnmapBuffer(GL_PIXEL_UNPACK_BUFFER);

// 异步上传
glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, width, height,
    GL_LUMINANCE, GL_UNSIGNED_BYTE, 0);
```

#### 6.4.2 多线程渲染

```
解码线程 ────> 帧队列 ────> GL 线程
                │
                └─ 使用双缓冲/环形队列
```

### 6.5 VR 全景播放

#### 6.5.1 球面映射算法

```cpp
// 顶点着色器：将平面网格映射到球面
void main() {
    float phi = uv.x * 2.0 * PI;        // 经度
    float theta = uv.y * PI;            // 纬度

    // 球面坐标转笛卡尔坐标
    float x = sin(theta) * cos(phi);
    float y = cos(theta);
    float z = sin(theta) * sin(phi);

    vec3 position = vec3(x, y, z) * radius;
    gl_Position = projection * view * vec4(position, 1.0);
}
```

#### 6.5.2 陀螺仪控制

```java
// 传感器监听
SensorManager sensorManager = getSystemService(SENSOR_SERVICE);
Sensor gyroscope = sensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE);
sensorManager.registerListener(listener, gyroscope,
    SensorManager.SENSOR_DELAY_GAME);

// 更新视角矩阵
public void onSensorChanged(SensorEvent event) {
    float rotX = event.values[0];
    float rotY = event.values[1];
    float rotZ = event.values[2];

    // 传递给 Native 层更新相机矩阵
    nativeUpdateCamera(rotX, rotY, rotZ);
}
```

---

## 7. 性能优化策略

### 7.1 内存优化

#### 7.1.1 对象池模式

```cpp
// AVFrame 对象池
class FramePool {
private:
    queue<AVFrame*> m_FrameQueue;
    mutex m_Mutex;

public:
    AVFrame* Acquire() {
        unique_lock<mutex> lock(m_Mutex);
        if(m_FrameQueue.empty()) {
            return av_frame_alloc();
        }
        AVFrame* frame = m_FrameQueue.front();
        m_FrameQueue.pop();
        return frame;
    }

    void Release(AVFrame* frame) {
        av_frame_unref(frame);
        unique_lock<mutex> lock(m_Mutex);
        m_FrameQueue.push(frame);
    }
};
```

#### 7.1.2 智能指针管理

```cpp
// 使用 RAII 自动释放资源
class AVFrameWrapper {
private:
    AVFrame* m_Frame;
public:
    AVFrameWrapper() : m_Frame(av_frame_alloc()) {}
    ~AVFrameWrapper() {
        av_frame_free(&m_Frame);
    }
    AVFrame* get() { return m_Frame; }
};
```

### 7.2 线程优化

#### 7.2.1 线程池

```cpp
class ThreadPool {
private:
    vector<thread> m_Threads;
    queue<function<void()>> m_Tasks;
    mutex m_Mutex;
    condition_variable m_Cond;

public:
    void AddTask(function<void()> task) {
        unique_lock<mutex> lock(m_Mutex);
        m_Tasks.push(task);
        m_Cond.notify_one();
    }
};
```

#### 7.2.2 减少锁竞争

```cpp
// 使用无锁队列（CAS 操作）
template<typename T>
class LockFreeQueue {
private:
    atomic<Node*> head;
    atomic<Node*> tail;

public:
    bool TryPush(const T& value);
    bool TryPop(T& value);
};
```

### 7.3 解码优化

#### 7.3.1 多线程解码

```cpp
// FFmpeg 多线程配置
m_AVCodecContext->thread_count = 4;  // 线程数
m_AVCodecContext->thread_type = FF_THREAD_FRAME;  // 帧级并行
```

#### 7.3.2 硬件加速

```cpp
// 优先使用硬件解码器
enum AVHWDeviceType type = av_hwdevice_find_type_by_name("mediacodec");
if(type != AV_HWDEVICE_TYPE_NONE) {
    av_hwdevice_ctx_create(&hw_device_ctx, type, NULL, NULL, 0);
    m_AVCodecContext->hw_device_ctx = av_buffer_ref(hw_device_ctx);
}
```

### 7.4 渲染优化

#### 7.4.1 帧率控制

```cpp
// 根据屏幕刷新率控制渲染
const int TARGET_FPS = 60;
const int FRAME_TIME = 1000 / TARGET_FPS;

long lastFrameTime = getCurrentTime();
while(rendering) {
    long currentTime = getCurrentTime();
    long deltaTime = currentTime - lastFrameTime;

    if(deltaTime >= FRAME_TIME) {
        renderFrame();
        lastFrameTime = currentTime;
    } else {
        usleep((FRAME_TIME - deltaTime) * 1000);
    }
}
```

#### 7.4.2 跳帧策略

```cpp
// 当解码速度跟不上播放速度时跳帧
if(m_VideoFrameQueue.Size() > MAX_QUEUE_SIZE) {
    // 丢弃非关键帧
    while(m_VideoFrameQueue.Size() > MIN_QUEUE_SIZE) {
        AVFrame* frame = m_VideoFrameQueue.Pop();
        if(frame->key_frame) {
            break;  // 保留关键帧
        }
        av_frame_free(&frame);
    }
}
```

---

## 8. 代码组织结构

### 8.1 目录结构

```
LearnFFmpeg/
├── app/
│   ├── src/
│   │   ├── main/
│   │   │   ├── java/com/byteflow/learnffmpeg/
│   │   │   │   ├── MainActivity.java              # 主界面
│   │   │   │   ├── GLMediaPlayerActivity.java     # OpenGL播放器
│   │   │   │   ├── VRMediaPlayerActivity.java     # VR播放器
│   │   │   │   ├── AVRecorderActivity.java        # 录制界面
│   │   │   │   ├── media/
│   │   │   │   │   └── FFMediaPlayer.java         # 播放器Java接口
│   │   │   │   ├── camera/
│   │   │   │   │   └── Camera2Wrapper.java        # 相机封装
│   │   │   │   └── view/
│   │   │   │       └── MyGLSurfaceView.java       # GL视图
│   │   │   │
│   │   │   ├── cpp/                               # Native 代码
│   │   │   │   ├── learn-ffmpeg.cpp               # JNI 接口实现
│   │   │   │   ├── CMakeLists.txt                 # CMake 构建脚本
│   │   │   │   │
│   │   │   │   ├── player/                        # 播放器模块
│   │   │   │   │   ├── FFMediaPlayer.h/cpp        # 软解播放器
│   │   │   │   │   ├── HWCodecPlayer.h/cpp        # 硬解播放器
│   │   │   │   │   ├── PlayerWrapper.h/cpp        # 播放器包装器
│   │   │   │   │   ├── MediaPlayer.h              # 播放器接口
│   │   │   │   │   │
│   │   │   │   │   ├── decoder/                   # 解码器
│   │   │   │   │   │   ├── Decoder.h              # 解码器接口
│   │   │   │   │   │   ├── DecoderBase.h/cpp      # 解码器基类
│   │   │   │   │   │   ├── VideoDecoder.h/cpp     # 视频解码器
│   │   │   │   │   │   └── AudioDecoder.h/cpp     # 音频解码器
│   │   │   │   │   │
│   │   │   │   │   └── render/                    # 渲染器
│   │   │   │   │       ├── video/
│   │   │   │   │       │   ├── VideoRender.h      # 视频渲染接口
│   │   │   │   │       │   ├── NativeRender.h/cpp # ANativeWindow渲染
│   │   │   │   │       │   ├── VideoGLRender.h/cpp# OpenGL渲染
│   │   │   │   │       │   ├── VRGLRender.h/cpp   # VR渲染
│   │   │   │   │       │   └── BaseGLRender.h     # GL渲染基类
│   │   │   │   │       │
│   │   │   │   │       └── audio/
│   │   │   │   │           ├── AudioRender.h      # 音频渲染接口
│   │   │   │   │           ├── OpenSLRender.h/cpp # OpenSL音频播放
│   │   │   │   │           └── AudioGLRender.h/cpp# 音频可视化
│   │   │   │   │
│   │   │   │   ├── recorder/                      # 录制模块
│   │   │   │   │   ├── MediaRecorder.h/cpp        # 编码录制
│   │   │   │   │   ├── MediaRecorderContext.h/cpp # 录制上下文
│   │   │   │   │   ├── SingleVideoRecorder.h/cpp  # 视频录制
│   │   │   │   │   ├── SingleAudioRecorder.h/cpp  # 音频录制
│   │   │   │   │   └── GLCameraRender.h/cpp       # 相机GL渲染
│   │   │   │   │
│   │   │   │   ├── common/                        # 公共模块
│   │   │   │   │   └── AVPacketQueue.h/cpp        # AVPacket队列
│   │   │   │   │
│   │   │   │   ├── util/                          # 工具类
│   │   │   │   │   ├── LogUtil.h                  # 日志工具
│   │   │   │   │   ├── GLUtils.h/cpp              # OpenGL工具
│   │   │   │   │   └── ImageDef.h                 # 图像定义
│   │   │   │   │
│   │   │   │   ├── include/                       # FFmpeg头文件
│   │   │   │   │   ├── libavcodec/
│   │   │   │   │   ├── libavformat/
│   │   │   │   │   ├── libavfilter/
│   │   │   │   │   ├── libavutil/
│   │   │   │   │   ├── libswresample/
│   │   │   │   │   └── libswscale/
│   │   │   │   │
│   │   │   │   └── glm/                           # OpenGL数学库
│   │   │   │
│   │   │   └── jniLibs/                           # 预编译库
│   │   │       ├── arm64-v8a/
│   │   │       │   ├── libavcodec.so
│   │   │       │   ├── libavformat.so
│   │   │       │   ├── libavfilter.so
│   │   │       │   ├── libavutil.so
│   │   │       │   ├── libswresample.so
│   │   │       │   ├── libswscale.so
│   │   │       │   ├── libfdk-aac.so
│   │   │       │   └── libx264.so
│   │   │       │
│   │   │       └── armeabi-v7a/
│   │   │           └── ...
│   │   │
│   │   └── build.gradle                           # 应用构建配置
│   │
│   └── build.gradle                               # 项目构建配置
│
├── doc/                                           # 文档资源
│   ├── learnffmpeg.apk                           # 示例APK
│   └── *.gif                                     # 演示动图
│
├── zgy_doc/                                      # 技术文档
│   └── 技术架构分析.md                            # 本文档
│
├── build.gradle                                  # 根构建配置
├── settings.gradle                               # 项目设置
└── README.md                                     # 项目说明
```

### 8.2 模块依赖关系

```
┌─────────────────────────────────────────────┐
│            Application Layer                │
│         (Activity, View, Adapter)           │
└────────────────┬────────────────────────────┘
                 │ 依赖
┌────────────────▼────────────────────────────┐
│              JNI Interface                  │
│           (learn-ffmpeg.cpp)                │
└────┬────────────────────────────────────┬───┘
     │                                    │
     ├─────────────┐         ┌────────────┤
     │             │         │            │
┌────▼─────┐  ┌───▼────┐ ┌──▼──────┐ ┌───▼─────┐
│  Player  │  │Recorder│ │ Common  │ │  Util   │
│  Module  │  │ Module │ │ Module  │ │ Module  │
└────┬─────┘  └───┬────┘ └──┬──────┘ └───┬─────┘
     │            │         │            │
     │            │         │            │
     └────────────┴─────────┴────────────┘
                  │
         ┌────────▼────────┐
         │  FFmpeg Libs    │
         │  Android APIs   │
         └─────────────────┘
```

### 8.3 关键接口定义

#### 8.3.1 播放器接口

```cpp
// MediaPlayer.h
class MediaPlayer {
public:
    virtual void Init(JNIEnv *env, jobject obj, char *url,
                      int renderType, jobject surface) = 0;
    virtual void UnInit() = 0;
    virtual void Play() = 0;
    virtual void Pause() = 0;
    virtual void Stop() = 0;
    virtual void SeekToPosition(float position) = 0;
    virtual long GetMediaParams(int paramType) = 0;
};
```

#### 8.3.2 解码器接口

```cpp
// Decoder.h
class Decoder {
public:
    virtual void Start() = 0;
    virtual void Pause() = 0;
    virtual void Stop() = 0;
    virtual float GetDuration() = 0;
    virtual void SeekToPosition(float position) = 0;
    virtual float GetCurrentPosition() = 0;
};
```

#### 8.3.3 渲染器接口

```cpp
// VideoRender.h
class VideoRender {
public:
    virtual void Init(int videoWidth, int videoHeight,
                      int *dstSize) = 0;
    virtual void RenderVideoFrame(AVFrame *frame) = 0;
    virtual void UnInit() = 0;
};

// AudioRender.h
class AudioRender {
public:
    virtual void Init() = 0;
    virtual void RenderAudioFrame(uint8_t *data, int dataSize) = 0;
    virtual void UnInit() = 0;
};
```

---

## 总结

### 项目优势

1. **架构清晰**: 分层明确，模块解耦，易于扩展
2. **功能完整**: 涵盖播放、录制、滤镜等核心功能
3. **性能优化**: 多线程、硬件加速、内存优化等
4. **跨平台**: 基于 FFmpeg，易于移植
5. **代码质量**: 注释详细，命名规范，设计模式应用合理

### 技术亮点

1. **多种渲染方式**: ANativeWindow、OpenGL ES、VR
2. **音视频同步**: 三种同步策略可选
3. **硬件加速**: MediaCodec 硬解码支持
4. **实时滤镜**: FFmpeg AVFilter 集成
5. **线程安全**: 完善的锁机制和队列管理

### 适用场景

- Android 音视频开发学习
- 短视频、直播应用开发
- VR 全景视频播放
- 音视频编辑应用
- 流媒体播放器开发

### 扩展方向

1. **功能扩展**
   - 添加更多滤镜效果
   - 支持多轨道音视频
   - 实现画中画模式
   - 添加字幕支持

2. **性能优化**
   - 使用 Vulkan 替代 OpenGL
   - 优化内存分配策略
   - 实现零拷贝数据传输

3. **平台扩展**
   - 移植到 iOS 平台
   - 支持 Windows/Mac 桌面端

---

**文档版本**: 1.0
**最后更新**: 2026-01-12
**作者**: 技术架构分析团队
